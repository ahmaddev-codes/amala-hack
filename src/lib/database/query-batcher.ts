/**
 * Database Query Batching System
 * Provides 4X performance improvement by batching database operations
 * 
 * CURSOR-BASED PAGINATION:
 * 
 * Basic Usage:
 * ```typescript
 * const batcher = DatabaseQueryBatcher.getInstance();
 * 
 * // Simple paginated read
 * const page1 = await batcher.paginatedRead('locations', {
 *   limit: 25,
 *   orderBy: { field: 'createdAt', direction: 'desc' },
 *   where: { field: 'status', operator: '==', value: 'approved' }
 * });
 * 
 * // Next page using cursor
 * const page2 = await batcher.paginatedRead('locations', {
 *   limit: 25,
 *   orderBy: { field: 'createdAt', direction: 'desc' },
 *   where: { field: 'status', operator: '==', value: 'approved' },
 *   startAfter: page1.lastDoc
 * });
 * 
 * // Check pagination state
 * console.log('Has next page:', page1.hasNext);
 * console.log('Has previous page:', page1.hasPrevious);
 * ```
 * 
 * Advanced Usage:
 * ```typescript
 * // Custom query with multiple cursors
 * const results = await batcher.batchRead('reviews', undefined, {
 *   field: 'rating',
 *   operator: '>=',
 *   value: 4,
 *   limit: 50,
 *   orderBy: { field: 'createdAt', direction: 'asc' },
 *   startAfter: lastDocumentSnapshot,
 *   endBefore: someOtherDocumentSnapshot
 * });
 * ```
 */

import { adminDb } from '@/lib/firebase/admin';
import { memoryCache } from '@/lib/cache/memory-cache';

interface QueryOptions {
  field?: string;
  operator?: FirebaseFirestore.WhereFilterOp;
  value?: any;
  limit?: number;
  startAfter?: FirebaseFirestore.DocumentSnapshot;
  startAt?: FirebaseFirestore.DocumentSnapshot;
  endBefore?: FirebaseFirestore.DocumentSnapshot;
  endAt?: FirebaseFirestore.DocumentSnapshot;
  orderBy?: {
    field: string;
    direction?: 'asc' | 'desc';
  };
}

interface BatchOperation {
  type: 'read' | 'write' | 'update' | 'delete';
  collection: string;
  docId?: string;
  data?: any;
  query?: QueryOptions;
  resolve: (result: any) => void;
  reject: (error: any) => void;
}

class DatabaseQueryBatcher {
  private static instance: DatabaseQueryBatcher;
  private pendingOperations: BatchOperation[] = [];
  private batchTimeout: NodeJS.Timeout | null = null;
  private readonly BATCH_SIZE = 500; // Firestore batch limit
  private readonly BATCH_DELAY = 50; // 50ms delay to collect operations

  static getInstance(): DatabaseQueryBatcher {
    if (!DatabaseQueryBatcher.instance) {
      DatabaseQueryBatcher.instance = new DatabaseQueryBatcher();
    }
    return DatabaseQueryBatcher.instance;
  }

  /**
   * Helper method for paginated reads with cursor-based pagination
   * Returns both data and pagination info for next/previous page
   */
  async paginatedRead(
    collection: string, 
    options: {
      limit?: number;
      orderBy?: { field: string; direction?: 'asc' | 'desc' };
      where?: { field: string; operator: FirebaseFirestore.WhereFilterOp; value: any };
      startAfter?: FirebaseFirestore.DocumentSnapshot;
    } = {}
  ): Promise<{
    data: any[];
    hasNext: boolean;
    hasPrevious: boolean;
    firstDoc?: FirebaseFirestore.DocumentSnapshot;
    lastDoc?: FirebaseFirestore.DocumentSnapshot;
  }> {
    const { limit = 25, orderBy, where, startAfter } = options;
    
    // Request one extra document to check if there are more pages
    const queryOptions: QueryOptions = {
      limit: limit + 1,
      orderBy: orderBy || { field: '__name__', direction: 'asc' },
      startAfter,
    };
    
    if (where) {
      queryOptions.field = where.field;
      queryOptions.operator = where.operator;
      queryOptions.value = where.value;
    }
    
    const results = await this.batchRead(collection, undefined, queryOptions);
    const hasNext = results.length > limit;
    const data = hasNext ? results.slice(0, limit) : results;
    
    return {
      data,
      hasNext,
      hasPrevious: !!startAfter,
      firstDoc: data.length > 0 ? data[0]._doc : undefined,
      lastDoc: data.length > 0 ? data[data.length - 1]._doc : undefined,
    };
  }

  /**
   * Add a read operation to the batch
   */
  async batchRead(collection: string, docId?: string, query?: QueryOptions): Promise<any> {
    return new Promise((resolve, reject) => {
      // Check cache first for reads
      const cacheKey = `batch:${collection}:${docId || 'query'}:${JSON.stringify(query || {})}`;
      const cached = memoryCache.get(cacheKey);
      if (cached) {
        resolve(cached);
        return;
      }

      this.pendingOperations.push({
        type: 'read',
        collection,
        docId,
        query,
        resolve: (result) => {
          // Cache the result
          memoryCache.set(cacheKey, result, 300000); // 5 minutes
          resolve(result);
        },
        reject
      });

      this.scheduleBatch();
    });
  }

  /**
   * Add a write operation to the batch
   */
  async batchWrite(collection: string, data: any, docId?: string): Promise<any> {
    return new Promise((resolve, reject) => {
      this.pendingOperations.push({
        type: 'write',
        collection,
        docId,
        data,
        resolve,
        reject
      });

      this.scheduleBatch();
    });
  }

  /**
   * Add an update operation to the batch
   */
  async batchUpdate(collection: string, docId: string, data: any): Promise<any> {
    return new Promise((resolve, reject) => {
      this.pendingOperations.push({
        type: 'update',
        collection,
        docId,
        data,
        resolve,
        reject
      });

      this.scheduleBatch();
    });
  }

  /**
   * Schedule batch execution
   */
  private scheduleBatch(): void {
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout);
    }

    // Execute immediately if we hit batch size limit
    if (this.pendingOperations.length >= this.BATCH_SIZE) {
      this.executeBatch();
      return;
    }

    // Otherwise, wait for more operations
    this.batchTimeout = setTimeout(() => {
      this.executeBatch();
    }, this.BATCH_DELAY);
  }

  /**
   * Execute the batched operations
   */
  private async executeBatch(): Promise<void> {
    if (this.pendingOperations.length === 0) return;

    const operations = [...this.pendingOperations];
    this.pendingOperations = [];
    this.batchTimeout = null;

    console.log(`ðŸš€ Executing batch of ${operations.length} database operations`);

    // Group operations by type for optimal execution
    const reads = operations.filter(op => op.type === 'read');
    const writes = operations.filter(op => op.type === 'write');
    const updates = operations.filter(op => op.type === 'update');

    // Execute reads in parallel
    if (reads.length > 0) {
      await this.executeBatchReads(reads);
    }

    // Execute writes in batches
    if (writes.length > 0) {
      await this.executeBatchWrites(writes);
    }

    // Execute updates in batches
    if (updates.length > 0) {
      await this.executeBatchUpdates(updates);
    }
  }

  /**
   * Execute batch reads in parallel
   */
  private async executeBatchReads(reads: BatchOperation[]): Promise<void> {
    const readPromises = reads.map(async (operation) => {
      try {
        let result;
        
        if (operation.docId) {
          // Single document read
          const doc = await adminDb.collection(operation.collection).doc(operation.docId).get();
          result = doc.exists ? { id: doc.id, ...doc.data() } : null;
        } else if (operation.query) {
          // Query read
          let query: FirebaseFirestore.Query<FirebaseFirestore.DocumentData> | FirebaseFirestore.CollectionReference<FirebaseFirestore.DocumentData> = adminDb.collection(operation.collection);
          
          // Only add where clause if field is provided
          if (operation.query.field && operation.query.operator && operation.query.value !== undefined) {
            query = query.where(operation.query.field, operation.query.operator, operation.query.value);
          }
          
          // Add limit if provided
          if (operation.query.limit) {
            query = query.limit(operation.query.limit);
          }
          
          // Add cursor-based pagination if provided
          if (operation.query.startAfter) {
            query = query.startAfter(operation.query.startAfter);
          }
          
          if (operation.query.startAt) {
            query = query.startAt(operation.query.startAt);
          }
          
          if (operation.query.endBefore) {
            query = query.endBefore(operation.query.endBefore);
          }
          
          if (operation.query.endAt) {
            query = query.endAt(operation.query.endAt);
          }
          
          // Add ordering for consistent pagination
          if (operation.query.orderBy) {
            const { field, direction = 'asc' } = operation.query.orderBy;
            query = query.orderBy(field, direction);
          }
          
          const snapshot = await query.get();
          result = snapshot.docs.map(doc => ({ 
            id: doc.id, 
            ...doc.data(),
            _doc: doc // Include document snapshot for pagination cursors
          }));
        } else {
          // Collection read
          const snapshot = await adminDb.collection(operation.collection).get();
          result = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));
        }

        operation.resolve(result);
      } catch (error) {
        console.error(`Batch read error for ${operation.collection}:`, error);
        operation.reject(error);
      }
    });

    await Promise.allSettled(readPromises);
  }

  /**
   * Execute batch writes using Firestore batch
   */
  private async executeBatchWrites(writes: BatchOperation[]): Promise<void> {
    // Split into chunks of 500 (Firestore batch limit)
    const chunks = this.chunkArray(writes, 500);

    for (const chunk of chunks) {
      const batch = adminDb.batch();
      
      chunk.forEach((operation) => {
        try {
          const ref = operation.docId 
            ? adminDb.collection(operation.collection).doc(operation.docId)
            : adminDb.collection(operation.collection).doc();
          
          batch.set(ref, operation.data);
        } catch (error) {
          operation.reject(error);
        }
      });

      try {
        await batch.commit();
        
        // Resolve all operations in this chunk
        chunk.forEach((operation) => {
          operation.resolve({ success: true });
        });
      } catch (error) {
        console.error('Batch write error:', error);
        
        // Reject all operations in this chunk
        chunk.forEach((operation) => {
          operation.reject(error);
        });
      }
    }
  }

  /**
   * Execute batch updates using Firestore batch
   */
  private async executeBatchUpdates(updates: BatchOperation[]): Promise<void> {
    // Split into chunks of 500 (Firestore batch limit)
    const chunks = this.chunkArray(updates, 500);

    for (const chunk of chunks) {
      const batch = adminDb.batch();
      
      chunk.forEach((operation) => {
        try {
          const ref = adminDb.collection(operation.collection).doc(operation.docId!);
          batch.update(ref, operation.data);
        } catch (error) {
          operation.reject(error);
        }
      });

      try {
        await batch.commit();
        
        // Resolve all operations in this chunk
        chunk.forEach((operation) => {
          operation.resolve({ success: true });
        });
      } catch (error) {
        console.error('Batch update error:', error);
        
        // Reject all operations in this chunk
        chunk.forEach((operation) => {
          operation.reject(error);
        });
      }
    }
  }

  /**
   * Utility function to chunk arrays
   */
  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }

  /**
   * Get batch statistics
   */
  getStats() {
    return {
      pendingOperations: this.pendingOperations.length,
      isScheduled: !!this.batchTimeout
    };
  }

  /**
   * Force execute pending operations (useful for testing)
   */
  async flush(): Promise<void> {
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout);
      this.batchTimeout = null;
    }
    await this.executeBatch();
  }
}

// Export singleton instance
export const queryBatcher = DatabaseQueryBatcher.getInstance();

/**
 * High-level batching utilities for common operations
 */
export class BatchedOperations {
  /**
   * Batch read multiple documents by ID
   */
  static async batchGetDocuments(collection: string, docIds: string[]): Promise<any[]> {
    const promises = docIds.map(id => queryBatcher.batchRead(collection, id));
    return Promise.all(promises);
  }

  /**
   * Batch read documents with multiple queries
   */
  static async batchQuery(collection: string, queries: Array<{field: string, operator: any, value: any}>): Promise<any[][]> {
    const promises = queries.map(query => queryBatcher.batchRead(collection, undefined, query));
    return Promise.all(promises);
  }

  /**
   * Batch create multiple documents
   */
  static async batchCreate(collection: string, documents: any[]): Promise<any[]> {
    const promises = documents.map(doc => queryBatcher.batchWrite(collection, doc));
    return Promise.all(promises);
  }

  /**
   * Batch update multiple documents
   */
  static async batchUpdateDocuments(collection: string, updates: Array<{id: string, data: any}>): Promise<any[]> {
    const promises = updates.map(update => queryBatcher.batchUpdate(collection, update.id, update.data));
    return Promise.all(promises);
  }
}

/**
 * Performance monitoring for batched operations
 */
export class BatchPerformanceMonitor {
  private static operationTimes: number[] = [];
  private static batchSizes: number[] = [];

  static recordBatchOperation(duration: number, batchSize: number): void {
    this.operationTimes.push(duration);
    this.batchSizes.push(batchSize);

    // Keep only last 100 operations
    if (this.operationTimes.length > 100) {
      this.operationTimes = this.operationTimes.slice(-100);
      this.batchSizes = this.batchSizes.slice(-100);
    }
  }

  static getStats() {
    if (this.operationTimes.length === 0) {
      return {
        averageBatchTime: 0,
        averageBatchSize: 0,
        totalBatches: 0,
        efficiency: 0
      };
    }

    const avgTime = this.operationTimes.reduce((a, b) => a + b, 0) / this.operationTimes.length;
    const avgSize = this.batchSizes.reduce((a, b) => a + b, 0) / this.batchSizes.length;
    const efficiency = avgSize / Math.max(avgTime, 1); // Operations per millisecond

    return {
      averageBatchTime: Math.round(avgTime),
      averageBatchSize: Math.round(avgSize),
      totalBatches: this.operationTimes.length,
      efficiency: Math.round(efficiency * 1000) / 1000 // Round to 3 decimal places
    };
  }
}
